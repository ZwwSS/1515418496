{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZwwSS/1515418496/blob/main/Human_Action_Detection_Artificial_Intelligence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive Mount\n"
      ],
      "metadata": {
        "id": "Z69pA6YQ10ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Z4scsj5zZl",
        "outputId": "03450dcb-43ad-4982-b234-bacd3ae3b3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Download"
      ],
      "metadata": {
        "id": "xbnWlR-750LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/emirhan_human_dataset.zip"
      ],
      "metadata": {
        "id": "ONqnxOJD57yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "x3AOu-dl57-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "bKmKMmOR2Cwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparing:"
      ],
      "metadata": {
        "id": "Y94AgESR2G0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=True,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    zca_epsilon=1e-06,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.0,\n",
        "    height_shift_range=0.0,\n",
        "    brightness_range=None,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    channel_shift_range=0.0,\n",
        "    fill_mode='nearest',\n",
        "    cval=0.0,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    rescale=1.0/255.0,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    dtype=None)\n",
        "test_datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=True,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    zca_epsilon=1e-06,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.0,\n",
        "    height_shift_range=0.0,\n",
        "    brightness_range=None,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    channel_shift_range=0.0,\n",
        "    fill_mode='nearest',\n",
        "    cval=0.0,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    rescale=1.0/255.0,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    dtype=None)\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/datasets/human_data/train_data\",target_size=(128, 128),\n",
        "                                                    batch_size=128,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    interpolation=\"nearest\")\n",
        "test_generator = test_datagen.flow_from_directory(\"/content/datasets/human_data/test_data\",target_size=(128, 128),\n",
        "                                                    batch_size=128,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    interpolation=\"nearest\")"
      ],
      "metadata": {
        "id": "NF_EOYst2LBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model structure and Code {Fuction}"
      ],
      "metadata": {
        "id": "zJS2hqz82OPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func(pre,name_model):\n",
        "    print('#####~Model => {} '.format(name_model))\n",
        "    pre_model = name_model(input_shape=(128,128, 3),\n",
        "                   include_top=False,\n",
        "                   weights='imagenet',\n",
        "                   pooling='avg')\n",
        "    pre_model.trainable = False\n",
        "    inputs = pre_model.input\n",
        "    x = Dense(64, activation='relu')(pre_model.output)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    outputs = Dense(15, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss = 'categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "    my_callbacks  = [EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=5,\n",
        "                              mode='auto')]\n",
        "\n",
        "    history = model.fit(train_generator,validation_data=test_generator,epochs=50,callbacks=my_callbacks,verbose=0)\n",
        "    # Plotting Accuracy, val_accuracy, loss, val_loss\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "    ax = ax.ravel()\n",
        "\n",
        "    for i, met in enumerate(['accuracy', 'loss']):\n",
        "        ax[i].plot(history.history[met])\n",
        "        ax[i].plot(history.history['val_' + met])\n",
        "        ax[i].set_title('Model {}'.format(met))\n",
        "        ax[i].set_xlabel('epochs')\n",
        "        ax[i].set_ylabel(met)\n",
        "        ax[i].legend(['Train', 'Validation'])\n",
        "    plt.show()\n",
        "\n",
        "    # Predict Data Test\n",
        "    pred = model.predict(test_generator)\n",
        "    pred = np.argmax(pred,axis=1)\n",
        "    labels = (train_generator.class_indices)\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "    pred = [labels[k] for k in pred]\n",
        "\n",
        "    print('\\033[01m              Classification_report \\033[0m')\n",
        "\n",
        "    print('\\033[01m              Results \\033[0m')\n",
        "    # Results\n",
        "    results = model.evaluate(test_generator, verbose=0)\n",
        "    print(\"    Test Loss:\\033[31m \\033[01m {:.5f} \\033[30m \\033[0m\".format(results[0]))\n",
        "    print(\"Test Accuracy:\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m\".format(results[1] * 100))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "He3HHOKk2U6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emir_model():\n",
        "  inp = Input(shape = (128,128,3))\n",
        "\n",
        "  x = Conv2D(32, (3,3), strides=(1, 1), padding='same', activation='tanh', use_bias=True)(inp)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(32, (3,3), strides=(1, 1), padding='same', activation='tanh', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n",
        "  x = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='tanh', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='tanh', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n",
        "  x = Conv2D(128, (3,3), strides=(1, 1), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(128, (3,3), strides=(1, 1), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n",
        "  x = Conv2D(256, (3,3), strides=(1, 1), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(256, (3,3), strides=(1, 1), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n",
        "  x = Conv2D(512, (3,3), strides=(1, 1), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(512, (3,3), strides=(1, 1), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n",
        "  x = Conv2D(1024, (3,3), strides=(2, 2), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(1024, (3,3), strides=(1, 1), padding='same', activation='relu', use_bias=True)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  x = Dense(15, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=inp, outputs= x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Q4w8KUlT2YLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func(name_model):\n",
        "\n",
        "    print('#####~Model => {} '.format(name_model))\n",
        "\n",
        "    model = emir_model()\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "    my_callbacks  = [EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=5,\n",
        "                              mode='auto')]\n",
        "\n",
        "    history = model.fit(train_generator,\n",
        "                        validation_data=test_generator,\n",
        "                        epochs=64,\n",
        "                        callbacks=my_callbacks,\n",
        "                        verbose=0,\n",
        "                        batch_size=128,)\n",
        "    # Plotting Accuracy, val_accuracy, loss, val_loss\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "    ax = ax.ravel()\n",
        "\n",
        "    for i, met in enumerate(['accuracy', 'loss']):\n",
        "        ax[i].plot(history.history[met])\n",
        "        ax[i].plot(history.history['val_' + met])\n",
        "        ax[i].set_title('Model {}'.format(met))\n",
        "        ax[i].set_xlabel('epochs')\n",
        "        ax[i].set_ylabel(met)\n",
        "        ax[i].legend(['Train', 'Validation'])\n",
        "    plt.show()\n",
        "\n",
        "    # Predict Data Test\n",
        "    pred = model.predict(test_generator)\n",
        "    pred = np.argmax(pred,axis=1)\n",
        "    labels = (train_generator.class_indices)\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "    pred = [labels[k] for k in pred]\n",
        "\n",
        "    print('\\033[01m              Classification_report \\033[0m')\n",
        "\n",
        "    print('\\033[01m              Results \\033[0m')\n",
        "    # Results\n",
        "    results = model.evaluate(test_generator, verbose=0)\n",
        "    print(\"    Test Loss:\\033[31m \\033[01m {:.5f} \\033[30m \\033[0m\".format(results[0]))\n",
        "    print(\"Test Accuracy:\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m\".format(results[1] * 100))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "0gcYyFKM2ZvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def depth(x, strides):\n",
        "    x = DepthwiseConv2D(3,strides=strides,padding='same',  use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "def single_conv_block(x,filters):\n",
        "    x = Conv2D(filters,1,use_bias=False)(x)\n",
        "    x= BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = SpatialDropout2D(0.2)(x)\n",
        "    return x\n",
        "def hidden_layers(x,filters,strides):\n",
        "    x = depth(x,strides)\n",
        "    x = single_conv_block(x, filters)\n",
        "    return x\n",
        "def EmirhanModel(input_shape=(128,128,3),n_classes = 15):\n",
        "    input = Input (input_shape)\n",
        "    x = Conv2D(32,3,strides=(2,2),padding = 'same', use_bias=False) (input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = ZeroPadding2D(padding=(2, 2))(x)\n",
        "    x = hidden_layers(x,64, strides=(1,1))\n",
        "    x = hidden_layers(x,128,strides=(2,2))\n",
        "    x = hidden_layers(x,128,strides=(1,1))\n",
        "    x = hidden_layers(x,256,strides=(2,2))\n",
        "    x = hidden_layers(x,256,strides=(1,1))\n",
        "    x = hidden_layers(x,512,strides=(2,2))\n",
        "    for _ in range(5):\n",
        "      x = hidden_layers(x,512,strides=(1,1))\n",
        "      x = hidden_layers(x,1024,strides=(2,2))\n",
        "      x = hidden_layers(x,1024,strides=(1,1))\n",
        "      x = GlobalAveragePooling2D()(x)\n",
        "      x = Dense(64, activation='relu')(x)\n",
        "      x = Dense(64, activation='relu')(x)\n",
        "      output = Dense(n_classes,activation='softmax')(x)\n",
        "      model = Model(input, output)\n",
        "      return model\n",
        "number_of_classes = 15\n",
        "input_shape = (128,128,3)"
      ],
      "metadata": {
        "id": "YmEEgU-j2bu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func(name_model):\n",
        "\n",
        "    print('#####~Model => {} '.format(name_model))\n",
        "\n",
        "    model = EmirhanModel(input_shape,number_of_classes)\n",
        "    print(model.summary())\n",
        "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "    my_callbacks  = [EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=5,\n",
        "                              mode='auto')]\n",
        "\n",
        "    history = model.fit(train_generator,\n",
        "                        validation_data=test_generator,\n",
        "                        epochs=64,\n",
        "                        callbacks=my_callbacks,\n",
        "                        verbose=0,\n",
        "                        batch_size=128,)\n",
        "    # Plotting Accuracy, val_accuracy, loss, val_loss\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "    ax = ax.ravel()\n",
        "\n",
        "    for i, met in enumerate(['accuracy', 'loss']):\n",
        "        ax[i].plot(history.history[met])\n",
        "        ax[i].plot(history.history['val_' + met])\n",
        "        ax[i].set_title('Model {}'.format(met))\n",
        "        ax[i].set_xlabel('epochs')\n",
        "        ax[i].set_ylabel(met)\n",
        "        ax[i].legend(['Train', 'Validation'])\n",
        "    plt.show()\n",
        "\n",
        "    # Predict Data Test\n",
        "    pred = model.predict(test_generator)\n",
        "    pred = np.argmax(pred,axis=1)\n",
        "    labels = (train_generator.class_indices)\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "    pred = [labels[k] for k in pred]\n",
        "\n",
        "    print('\\033[01m              Classification_report \\033[0m')\n",
        "\n",
        "    print('\\033[01m              Results \\033[0m')\n",
        "    # Results\n",
        "    results = model.evaluate(test_generator, verbose=0)\n",
        "    print(\"    Test Loss:\\033[31m \\033[01m {:.5f} \\033[30m \\033[0m\".format(results[0]))\n",
        "    print(\"Test Accuracy:\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m\".format(results[1] * 100))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "dmcbQbyi2fdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep Models and My Model Benchmark Scores"
      ],
      "metadata": {
        "id": "kGkOIqvL288_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG19**"
      ],
      "metadata": {
        "id": "1Xl-W9f73xzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "result_VGG19 = func(preprocess_input,VGG19)"
      ],
      "metadata": {
        "id": "RSy4pQrH30Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16"
      ],
      "metadata": {
        "id": "31c2Sa2t36mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "result_VGG16 = func(preprocess_input,VGG16)"
      ],
      "metadata": {
        "id": "iOHX9CZ536rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50"
      ],
      "metadata": {
        "id": "8ykYQgLw36v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "result_ResNet50 = func(preprocess_input,ResNet50)"
      ],
      "metadata": {
        "id": "LXAy4xEw360X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet101"
      ],
      "metadata": {
        "id": "a26_rkjk4Tjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "result_ResNet101 = func(preprocess_input,ResNet101)"
      ],
      "metadata": {
        "id": "NtUMIk6d4TrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet"
      ],
      "metadata": {
        "id": "BmK48CdG4iG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "result_MobileNet = func(preprocess_input,MobileNet)"
      ],
      "metadata": {
        "id": "SolXFUEx4m9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet201"
      ],
      "metadata": {
        "id": "8ZjMOYlg4yBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "result_DenseNet201 = func(preprocess_input,DenseNet201)"
      ],
      "metadata": {
        "id": "C-xiQl2040eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB7"
      ],
      "metadata": {
        "id": "Kyt9dPkX42eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "result_Eff = func(preprocess_input,EfficientNetB7)"
      ],
      "metadata": {
        "id": "omvNpdjr42ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xception"
      ],
      "metadata": {
        "id": "Do22IHoH46Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "result_Xception = func(preprocess_input,Xception)"
      ],
      "metadata": {
        "id": "rWcQShTy46g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "InceptionResNetV2"
      ],
      "metadata": {
        "id": "GK-w0dZj46l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
        "result_InResNetV2 = func(preprocess_input,InceptionResNetV2)"
      ],
      "metadata": {
        "id": "iIlxI-n646rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Emirhan"
      ],
      "metadata": {
        "id": "F5OtpjdJ5DVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Emirhan_Human_Action_Detection_with_Artificial_Intelligence\"\n",
        "result_emirhan = func(model_name)"
      ],
      "metadata": {
        "id": "MOErZWC95GF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally Result of Table (DataFrame- Pandas)"
      ],
      "metadata": {
        "id": "sfMYmE7b5QWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_result_table = pd.DataFrame({'Model':['Emirhan_Model','VGG16','VGG19','ResNet50','ResNet101','MobileNet','InceptionResNetV2',\n",
        "                               'DenseNet201','Xception','EfficientNetB7'],\n",
        "                      'Accuracy':[result_emirhan[1],result_VGG16[1], result_VGG19[1], result_ResNet50[1], result_ResNet101[1],\n",
        "                                  result_MobileNet[1],result_InResNetV2[1],result_DenseNet201[1],result_Xception[1],\n",
        "                                 result_Eff[1]]})"
      ],
      "metadata": {
        "id": "zP_BQRkw5Rw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_result_table"
      ],
      "metadata": {
        "id": "8ne5iu4s5US1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "plots = sns.barplot(x='Model', y='Accuracy', data=accuracy_result_table)\n",
        "for bar in plots.patches:\n",
        "    plots.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=15, xytext=(0, 9),\n",
        "                   textcoords='offset points')\n",
        "\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(rotation=20);"
      ],
      "metadata": {
        "id": "PfTrI_8w5V-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_result_table = pd.DataFrame({'Model':['Emirhan_Model','VGG16','VGG19','ResNet50','ResNet101','MobileNet','InceptionResNetV2',\n",
        "                               'DenseNet201','Xception','EfficientNetB7'],\n",
        "                      'Loss':[result_emirhan[0],result_VGG16[0], result_VGG19[0], result_ResNet50[0], result_ResNet101[0],\n",
        "                                  result_MobileNet[0],result_InResNetV2[0],result_DenseNet201[0],result_Xception[0],\n",
        "                                 result_Eff[0]]})"
      ],
      "metadata": {
        "id": "Foyzb-EX5Xm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_result_table"
      ],
      "metadata": {
        "id": "BOJGoxnb5YuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "plots = sns.barplot(x='Model', y='Loss', data=loss_result_table)\n",
        "for bar in plots.patches:\n",
        "    plots.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=15, xytext=(0, 9),\n",
        "                   textcoords='offset points')\n",
        "\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks(rotation=20);"
      ],
      "metadata": {
        "id": "re7GOz3t5Zk8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}